{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model Train\n",
    "\n",
    "In this notebook a simple overview is provided to train the CNN model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T14:17:38.152068Z",
     "start_time": "2021-01-28T14:17:38.145241Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T14:17:39.436665Z",
     "start_time": "2021-01-28T14:17:38.152986Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}   \n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from utils.dataset import get_CNN_generators\n",
    "from utils.jpg_to_jpeg_converter import convert_jpg_to_jpeg\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T14:17:39.485046Z",
     "start_time": "2021-01-28T14:17:39.438120Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None))\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus, tf.version)\n",
    "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T14:17:39.502857Z",
     "start_time": "2021-01-28T14:17:39.486169Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change variables to point at the locations of the training data and where you want to save the models\n",
    "data_path = './Data_jpeg'\n",
    "save_dir = './bin/'\n",
    "# Define the different settings for the model\n",
    "# (epochs, learning rate, batch size)\n",
    "settings = [(10, 5e-5, 32), (10, 5e-5, 64), (10, 1e-4, 32), (20, 5e-5, 32)]\n",
    "name = ['base', 'bs_64', 'lr_1e-4', '20_epochs']\n",
    "\n",
    "IMAGE_SIZE = 96\n",
    "\n",
    "# size of both training sets\n",
    "SIZE_TRAIN = 144000\n",
    "SIZE_VAL = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Convert the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataset from jpg to jpeg. \n",
    "# input data path, output data path\n",
    "# check if the data is already converted\n",
    "if not os.path.exists(\"./Data_jpeg/\"):\n",
    "    convert_jpg_to_jpeg(\"./Data/\", \"./Data_jpeg/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T14:21:46.634945Z",
     "start_time": "2021-01-28T14:21:46.311296Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_model(kernel_size=(3,3), pool_size=(4,4), first_filters=32, second_filters=64, learning_rate = 5e-5):\n",
    "\n",
    "     # build the model\n",
    "     model = Sequential()\n",
    "     model.add(tf.keras.Input((IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "     model.add(Conv2D(first_filters, kernel_size, activation = 'relu', padding = 'same', input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)))\n",
    "     model.add(MaxPool2D(pool_size = pool_size))\n",
    "\n",
    "     model.add(Conv2D(second_filters, kernel_size, activation = 'relu', padding = 'same'))\n",
    "     model.add(MaxPool2D(pool_size = pool_size))\n",
    "\n",
    "\n",
    "     model.add(Flatten())\n",
    "     model.add(Dense(75, activation = 'relu'))\n",
    "     model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "     # compile the model\n",
    "     model.compile(SGD(learning_rate=learning_rate, momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T17:38:06.189031Z",
     "start_time": "2021-01-25T17:38:05.460415Z"
    }
   },
   "source": [
    "# 3.0 Train the Model for each parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T14:25:09.510250Z",
     "start_time": "2021-01-28T14:24:56.018640Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(settings)):\n",
    "     model_name = name[i]\n",
    "     \n",
    "     model_filepath = model_name + '.json'\n",
    "     weights_filepath = model_name + '_weights.hdf5'\n",
    "     model_filepath = os.path.join(save_dir, model_name + '.json')\n",
    "     weights_filepath = os.path.join(save_dir, model_name + '_weights.hdf5')\n",
    "\n",
    "     # get the model\n",
    "     model = get_model(learning_rate=settings[i][1])\n",
    "     print('Model name: ', model_name)\n",
    "\n",
    "\n",
    "\n",
    "     # get the data generators\n",
    "     train_gen, val_gen = get_CNN_generators(data_path, image_size=IMAGE_SIZE, train_batch_size=settings[i][2], val_batch_size=settings[i][2])\n",
    "\n",
    "\n",
    "     model_json = model.to_json() # serialize model to JSON\n",
    "     with open(model_filepath, 'w') as json_file:\n",
    "          json_file.write(model_json)\n",
    "\n",
    "\n",
    "     # define the model checkpoint and Tensorboard callbacks\n",
    "     checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "     tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "     callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "\n",
    "     # train the model\n",
    "     train_steps = SIZE_TRAIN//settings[i][2]\n",
    "     val_steps = SIZE_VAL//settings[i][2]\n",
    "\n",
    "     history = model.fit(train_gen, steps_per_epoch=train_steps,\n",
    "                         validation_data=val_gen,\n",
    "                         validation_steps=val_steps,\n",
    "                         epochs=settings[i][0],\n",
    "                         callbacks=callbacks_list,\n",
    "                         batch_size=settings[i][2])\n",
    "     print('Training done for ', model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
